<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mike Tobias on Mike Tobias</title>
    <link>https://mct-dev.github.io/</link>
    <description>Recent content in Mike Tobias on Mike Tobias</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Handling SQS Messages with Serverless Functions</title>
      <link>https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/</guid>
      <description>

&lt;p&gt;This is part 3 of the series.  Feel free to skip around to other sections using the links below.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/aws-sqs-microservice-pipeline/&#34;&gt;Case Study and Grooming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/&#34;&gt;Simple API Endpoints with Serverless and Lambda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/&#34;&gt;Handling SQS Messages with Serverless Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;

&lt;p&gt;In our &lt;a href=&#34;https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/&#34;&gt;last post&lt;/a&gt; we set up an API endpoint and a serverless function which will receive voting data, add it to our SQS Queue, then publish to an SNS topic. Now, we need to build a function which will consume messages from this SQS Queue and add them to a database. We&amp;rsquo;ll use DynamoDB for our database because it&amp;rsquo;s scalable, reliable, NoSQL, and integrates well with our pipeline.&lt;/p&gt;

&lt;h2 id=&#34;the-new-function&#34;&gt;The new function&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s get right to it. Here&amp;rsquo;s our second function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;quot;use strict&amp;quot;;
const AWS = require(&amp;quot;aws-sdk&amp;quot;);
const sqs = new AWS.SQS({apiVersion: &amp;quot;2012-11-05&amp;quot;});
const db = new AWS.DynamoDB.DocumentClient({apiVersion: &amp;quot;2012-08-10&amp;quot;});

AWS.config.update({region: &amp;quot;us-east-1&amp;quot;});

const getQueueUrl = async () =&amp;gt; {
  let queueUrlResponse = await sqs.getQueueUrl({
    QueueName: process.env.SQS_QUEUE_NAME
  }).promise();

  return queueUrlResponse.QueueUrl;
};

const getMessages = async (queueUrl) =&amp;gt; {
  let messagesResponse = await sqs.receiveMessage({
    QueueUrl: queueUrl,
    WaitTimeSeconds: 5,
    MaxNumberOfMessages: 10
  }).promise();

  return messagesResponse &amp;amp;&amp;amp; messagesResponse.Messages
    ? messagesResponse.Messages
    : [];
};

module.exports.handleSqsMessages = async (event) =&amp;gt; {
  const dbTableName = process.env.DYNAMODB_TABLE;
  const sqsQueueName = process.env.SQS_QUEUE_NAME;
  const timestamp = new Date().getTime();

  if (event &amp;amp;&amp;amp; event.Records) {
    console.log(&amp;quot;Event Records: &amp;quot;, event.Records);
    let message = event.Records[0].Message;
    console.log(&amp;quot;Event received.&amp;quot;);
    console.log(`Event SNS Message: ${message}.`);
  }

  let canProcessMessages = true;
  let queueUrl = await getQueueUrl(sqsQueueName);

  if (!queueUrl) {
    canProcessMessages = false;
  }

  while (canProcessMessages) {
    let messages = await getMessages(queueUrl);

    if (!messages || !messages.length) {
      console.log(`No messages found in queue ${sqsQueueName}.`);
      canProcessMessages = false;
      return 0;
    }

    for (let msg of messages) {
      let msgId = msg.MessageId;
      let msgBody = JSON.parse(msg.Body);

      if (!(msgId &amp;amp;&amp;amp; msgBody)) {
        // go to next message
        continue;
      }
      
      console.log(`processing message (id: ${msgId})`);

      try {
        await db.put({
          TableName: dbTableName,
          Item: {
            id: msgId,
            VoteData: msgBody,
            createdAt: timestamp,
            updatedAt: timestamp
          }
        }).promise();

        console.log(`DB PUT successful! Message Id: ${msgId}`);
      } catch (err) {
        console.error(`DB PUT failed! Message Id: ${msgId}. Error: ${err}`);
        return 1;
      }

      try {
        await sqs.deleteMessage({
          QueueUrl: queueUrl,
          ReceiptHandle: msg.ReceiptHandle
        }).promise();

        console.log(`Message deleted from SQS Queue. Queue URL: ${queueUrl} | Message Receipt Handle: ${msg.ReceiptHandle}`);
      } catch (err) {
        console.error(`Message deletion FAILED. Message Receipt Handle: ${msg.ReceiptHandle}. Error: ${err}`);
        return 1;
      }
    }
  }

  return 0;
};
&amp;quot;use strict&amp;quot;;
const AWS = require(&amp;quot;aws-sdk&amp;quot;);
const sqs = new AWS.SQS({apiVersion: &amp;quot;2012-11-05&amp;quot;});
const db = new AWS.DynamoDB.DocumentClient({apiVersion: &amp;quot;2012-08-10&amp;quot;});

AWS.config.update({region: &amp;quot;us-east-1&amp;quot;});

const getQueueUrl = async () =&amp;gt; {
  let queueUrlResponse = await sqs.getQueueUrl({
    QueueName: process.env.SQS_QUEUE_NAME
  }).promise();

  return queueUrlResponse.QueueUrl;
};

const getMessages = async (queueUrl) =&amp;gt; {
  let messagesResponse = await sqs.receiveMessage({
    QueueUrl: queueUrl,
    WaitTimeSeconds: 5,
    MaxNumberOfMessages: 10
  }).promise();

  return messagesResponse &amp;amp;&amp;amp; messagesResponse.Messages
    ? messagesResponse.Messages
    : [];
};

module.exports.handleSqsMessages = async (event) =&amp;gt; {
  const dbTableName = process.env.DYNAMODB_TABLE;
  const sqsQueueName = process.env.SQS_QUEUE_NAME;
  const timestamp = new Date().getTime();

  if (event &amp;amp;&amp;amp; event.Records) {
    console.log(&amp;quot;Event Records: &amp;quot;, event.Records);
    let message = event.Records[0].Message;
    console.log(&amp;quot;Event received.&amp;quot;);
    console.log(`Event SNS Message: ${message}.`);
  }

  let canProcessMessages = true;
  let queueUrl = await getQueueUrl(sqsQueueName);

  if (!queueUrl) {
    canProcessMessages = false;
  }

  while (canProcessMessages) {
    let messages = await getMessages(queueUrl);

    if (!messages || !messages.length) {
      console.log(`No messages found in queue ${sqsQueueName}.`);
      canProcessMessages = false;
      return 0;
    }

    for (let msg of messages) {
      let msgId = msg.MessageId;
      let msgBody = JSON.parse(msg.Body);

      if (!(msgId &amp;amp;&amp;amp; msgBody)) {
        // go to next message
        continue;
      }
      
      console.log(`processing message (id: ${msgId})`);

      try {
        await db.put({
          TableName: dbTableName,
          Item: {
            id: msgId,
            VoteData: msgBody,
            createdAt: timestamp,
            updatedAt: timestamp
          }
        }).promise();

        console.log(`DB PUT successful! Message Id: ${msgId}`);
      } catch (err) {
        console.error(`DB PUT failed! Message Id: ${msgId}. Error: ${err}`);
        return 1;
      }

      try {
        await sqs.deleteMessage({
          QueueUrl: queueUrl,
          ReceiptHandle: msg.ReceiptHandle
        }).promise();

        console.log(`Message deleted from SQS Queue. Queue URL: ${queueUrl} | Message Receipt Handle: ${msg.ReceiptHandle}`);
      } catch (err) {
        console.error(`Message deletion FAILED. Message Receipt Handle: ${msg.ReceiptHandle}. Error: ${err}`);
        return 1;
      }
    }
  }

  return 0;
};

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what are we working with here? We&amp;rsquo;ve got a couple &amp;ldquo;helper&amp;rdquo; functions at the top for getting the SQS queue URL and retrieving messages from this queue. Then, we&amp;rsquo;ve got the main function. In there, we&amp;rsquo;re really only doing a few things: logging the event that triggered this function (using &lt;code&gt;console.log&lt;/code&gt;), collecting messages from the SQS queue, adding all messages found to our database, then deleting all the messages we&amp;rsquo;ve processed from the SQS queue. Let&amp;rsquo;s go over it a little more in detail.&lt;/p&gt;

&lt;p&gt;First we first collect our databse table name and SQS queue name from our environment variables. You&amp;rsquo;ll notice the &lt;code&gt;DYNAMODB_TABLE&lt;/code&gt; environment variable is a new one. We&amp;rsquo;ve added that to the &lt;code&gt;serverless.yml&lt;/code&gt; file, which well see in a moment. We also establish a timestamp which we can use later on in the function.&lt;/p&gt;

&lt;p&gt;Next, we log the event &lt;code&gt;Records&lt;/code&gt; if any are found. This is only used for tracking purposes. By adding a few of these &lt;code&gt;console.log&lt;/code&gt; statements throughout our function, we are then able to look into our logs in AWS CloudWatch to see a detailed accounting of what happened when this function ran.  The &lt;code&gt;Records&lt;/code&gt; object will exist only if the function was triggered by an SNS publish.&lt;/p&gt;

&lt;p&gt;Now we collect our SQS queue URL and begin processing messages. Assuming a queue URL was returned, we&amp;rsquo;ll establish a loop which only closes when we decide we can no longer process messages (&lt;code&gt;canProcessMessages=false&lt;/code&gt;). In the loop, we grab the messages using our &lt;code&gt;getMessages&lt;/code&gt; function. If this returns no messages, we stop the loop and the function ends.  However, if it returns some messages we process each one of them. This means collecting the &lt;code&gt;MessageId&lt;/code&gt; and the message &lt;code&gt;Body&lt;/code&gt;, then running a &lt;code&gt;PUT&lt;/code&gt; to our dynamoDB table. The format of the object we pass to this &lt;code&gt;db.put&lt;/code&gt; is important. You can find more info about this formatting in the &lt;a href=&#34;https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB/DocumentClient.html#put-property&#34;&gt;nodejs aws-sdk docs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If any errors were hit on our way to this point, we&amp;rsquo;ve logged them to AWS CloudWatch and returned a non-zero value, ending the function.  But, if we made it this far without errors, we delete the message from our SQS queue and then we&amp;rsquo;re done!&lt;/p&gt;

&lt;h2 id=&#34;the-updated-yaml-file&#34;&gt;The updated yaml file&lt;/h2&gt;

&lt;p&gt;So, now comes the second major part of this segment of our pipeline: the &lt;code&gt;serverless.yml&lt;/code&gt; file. Here&amp;rsquo;s the updated version. Take a quick read.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;service: voting-app

provider:
  name: aws
  runtime: nodejs8.10
  stage: ${opt:stage, &#39;dev&#39;}
  region: ${opt:region, &#39;us-east-1&#39;}
  environment:
    DYNAMODB_TABLE: ${file(../voting-db/serverless.yml):service}-${self:provider.stage}-table
    SQS_QUEUE_NAME: ${self:service}-${self:provider.stage}-queue
    SNS_TOPIC: ${self:service}-${self:provider.stage}-topic
  iamRoleStatements:
    - Effect: Allow
      Action:
        - SQS:*
      Resource: {&amp;quot;Fn::Join&amp;quot; : [&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sqs:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SQS_QUEUE_NAME}&amp;quot; ] ] }
    - Effect: Allow
      Action:
        - dynamoDB:*
      Resource: {&amp;quot;Fn::Join&amp;quot; : [&amp;quot;&amp;quot;, [&amp;quot;arn:aws:dynamodb:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:table/${self:provider.environment.DYNAMODB_TABLE}&amp;quot; ] ] }
    - Effect: Allow
      Action:
        - SNS:*
      Resource: {&amp;quot;Fn::Join&amp;quot;:[&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sns:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SNS_TOPIC}&amp;quot;]]}

functions:
  post-vote:
    handler: post-vote.postVote
    events:
      - http:
          path: vote
          method: post
    environment:
      SNS_TOPIC_ARN: {&amp;quot;Fn::Join&amp;quot;:[&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sns:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SNS_TOPIC}&amp;quot;]]}
  handle-votes:
    handler: handle-votes.handleSqsMessages
    events:
      - schedule: rate(1 minute)
      - sns: ${self:provider.environment.SNS_TOPIC}

resources:
  Resources:
    VotesQueue:
      Type: &#39;AWS::SQS::Queue&#39;
      Properties:
        QueueName: ${self:provider.environment.SQS_QUEUE_NAME}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The new additions to point out here are not many. We&amp;rsquo;ve added the new environment variable, &lt;code&gt;DYNAMODB_TABLE&lt;/code&gt;. We added a new &lt;code&gt;iamRoleStatement&lt;/code&gt; which allows our functions access to dynamoDB.  And we added a new &lt;code&gt;handle-votes&lt;/code&gt; section in our &lt;code&gt;functions&lt;/code&gt;. This is the interesting bit!  This function has 2 &lt;code&gt;events&lt;/code&gt; set up for it.  One of these events is a &lt;code&gt;schedule&lt;/code&gt; which will trigger the function every &amp;ldquo;1 minute&amp;rdquo;.  This is probably excessive, and could be increased to a larger amount of time in production.  The idea with this schedule is just to have the function run some &amp;ldquo;cleanup&amp;rdquo; every now and then to make sure that all of our SQS messages get handled.  However, we should be able to rely on the next event to do most of the work here.  The &lt;code&gt;sns&lt;/code&gt; event will subscribe our &lt;code&gt;handle-votes&lt;/code&gt; function to a specific SNS Topic, which we&amp;rsquo;ve provided by referencing an environment variable in this file.  Since the function is subscribed, it will be triggered when our &lt;em&gt;first&lt;/em&gt; function (&lt;code&gt;post-vote&lt;/code&gt;) publishes a message to this topic.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s all for this file!  But what about DynamoDB?  We aren&amp;rsquo;t creating that resource here, are we?  Correct!  The reason we don&amp;rsquo;t include databases here is that, in a production environment, databases usually exist already or at least won&amp;rsquo;t be changed very often.  This serverless file is designed so that you can create, update, and destroy all of these resources and services at will. This isn&amp;rsquo;t the approach you&amp;rsquo;d want to take with your data, however.&lt;/p&gt;

&lt;p&gt;If you did want to create a Dynamo database and table using serverless, maybe for testing purposes, you can still do that!  Serverless has the power!  The best plan here would be to create a new &lt;code&gt;serverless.yml&lt;/code&gt; file somewhere &lt;strong&gt;outside&lt;/strong&gt; of your &lt;code&gt;voting-functions&lt;/code&gt; directory.  The idea is to have a different area where you can run your &lt;code&gt;serverless&lt;/code&gt; command in the terminal, so that when you update your Lambda functions and other resources you won&amp;rsquo;t also try to re-deploy your DynamoDB table when you update these functions using &lt;code&gt;serverless deploy&lt;/code&gt;.  So, what would that new file look like for creating your database?  Here you go:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;service: voting-db

custom:
  tableName: ${self:service}-${self:provider.stage}-table

provider:
  name: aws
  runtime: nodejs8.10
  stage: ${opt:stage, &#39;dev&#39;}
  region: ${opt:region, &#39;us-east-1&#39;}

resources:
  Resources:
    VotesDynamoDbTable:
      Type: &#39;AWS::DynamoDB::Table&#39;
      DeletionPolicy: Retain
      Properties:
        AttributeDefinitions:
          - AttributeName: id
            AttributeType: S
        KeySchema:
          - AttributeName: id
            KeyType: HASH
        ProvisionedThroughput:
          ReadCapacityUnits: 1
          WriteCapacityUnits: 1
        TableName: ${self:custom.tableName}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A few sections here probably look familiar to you.  The resources section creates our resources and in it we&amp;rsquo;ve established our &lt;code&gt;VotesDynamoDbTable&lt;/code&gt;.  Tables in DynamoDB require at least 1 &lt;code&gt;Key&lt;/code&gt; to serve as the primary key.  This is created by first establishing an &lt;code&gt;AttributeDefinition&lt;/code&gt; and then creating our &lt;code&gt;KeySchema&lt;/code&gt; which references the name of our newly created Attribute.  We then provide the &lt;code&gt;TableName&lt;/code&gt; at the end.  Check out the &lt;a href=&#34;https://github.com/serverless/examples/blob/master/aws-node-rest-api-with-dynamodb/serverless.yml&#34;&gt;serverless examples repo&lt;/a&gt; for more examples of using dynamodb with the serverless framework.&lt;/p&gt;

&lt;p&gt;We also use a new section here called &lt;code&gt;custom&lt;/code&gt;.  This is a good area for you to define local variables for your file. Since this new serverless service doesn&amp;rsquo;t need to use the dynamoDB table name anywhere else, we can just put it in this &lt;code&gt;custom&lt;/code&gt; section for reference within this file.&lt;/p&gt;

&lt;p&gt;Now, you can run &lt;code&gt;serverless deploy&lt;/code&gt; in this directory to create this DynamoDB table!&lt;/p&gt;

&lt;h2 id=&#34;other-thoughts&#34;&gt;Other thoughts&lt;/h2&gt;

&lt;p&gt;One thought you may have had while reading this is:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What if we fail to delete the SQS message after processing it? Wouldn&amp;rsquo;t we end up adding a duplicate to the database later on?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;No. The &lt;code&gt;MessageId&lt;/code&gt; value provided by each message from our SQS queue will remain the same if we fail to delete that item. We will, indeed, end up collecting this message again later on, but since we&amp;rsquo;re using this value as our primary key in the DynamoDB table we&amp;rsquo;d avoid duplicating it.  When you try to put a record in a DynamoDB table and the record&amp;rsquo;s primary key already exists, DyanmoDB will wimply simply &lt;a href=&#34;https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_PutItem.html&#34;&gt;overwrite the old item with the new&lt;/a&gt; one. Since the data from our SQS message will not have changed, this would be alright with us!&lt;/p&gt;

&lt;h2 id=&#34;finishing-up&#34;&gt;Finishing Up&lt;/h2&gt;

&lt;p&gt;We have now successfully built our pipeline!  To sum it all up, we now have:
* An API endpoint where a client can submit voting data.
* A serverless Lambda function which will accept data from this endpoint, add it to a SQS queue, and publish an SNS message.
* Another serverless Lambda function which will trigger when a message is published to this SNS topic OR on a timed schedule. This function will collect votes from the SQS queue, add them to a DynamoDB table, and then delete them from the queue.
* A DynamoDB table to store the voting data.&lt;/p&gt;

&lt;p&gt;This pipeline is extremely scalable and can be created, updated, and deleted at the push of a button! You can try it now by cloning &lt;a href=&#34;https://github.com/mct-dev/voting-app&#34;&gt;this repo&lt;/a&gt; and running &lt;code&gt;npm deploy&lt;/code&gt;. To remove all of these resources from AWS, just run &lt;code&gt;npm run remove&lt;/code&gt;.  Keep in mind that you&amp;rsquo;ll need to be authenticated to your AWS account for any of this to work.  You can find out how to do this &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One important note: if you&amp;rsquo;re creating your database with the serverless template I&amp;rsquo;ve shown above, you won&amp;rsquo;t be able to remove it with a &lt;code&gt;serverless remove&lt;/code&gt; command.  This is for all the same &amp;ldquo;data integrity&amp;rdquo; and safety reasons as we mentioned before.  AWS won&amp;rsquo;t let you destroy database things without you explicitly telling it to do so.&lt;/p&gt;

&lt;p&gt;And with that, I think that&amp;rsquo;ll do it for now.  If you&amp;rsquo;re still reading, I appreciate you sticking it out.  Be sure to check in for the next one.  I&amp;rsquo;ll make sure we build something even cooler. :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simple API Endpoints with Serverless and Lambda</title>
      <link>https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/</link>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/</guid>
      <description>

&lt;p&gt;This is part 2 of the series.  Feel free to skip around to other sections using the links below.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/aws-sqs-microservice-pipeline/&#34;&gt;Case Study and Grooming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/&#34;&gt;Simple API Endpoints with Serverless and Lambda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/&#34;&gt;Handling SQS Messages with Serverless Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;

&lt;p&gt;Our objective in this segment is to create an API endpoint attached to a Lambda function which will handle vote submissions, adding each vote to an SQS Message Queue to be processed at a later time.  This is the first part of our voting pipeline, an application that we&amp;rsquo;re designing as part of a fictitious case study.  See [part 1]() of this series for more info on that.&lt;/p&gt;

&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll be using the &lt;a href=&#34;https://serverless.com/framework/&#34;&gt;Serverless Framework&lt;/a&gt; to build our &amp;ldquo;back-end&amp;rdquo; functions and API endpoints.  This framework is platform-agnostic, meaning we don&amp;rsquo;t &lt;em&gt;have&lt;/em&gt; to use AWS as our cloud platform.  We could use other providers as well!  The serverless functions are also a great choice here because they are efficient, cost-effective, and extremely scalable.&lt;/p&gt;

&lt;p&gt;Also, if you&amp;rsquo;re unfamiliar with any of the subjects discussed in this post, I&amp;rsquo;d very much encourage you to read through some of the online documentation available for them.  Maybe do some googling or run through some of the &amp;ldquo;Getting Started&amp;rdquo; sections.  There&amp;rsquo;s quite a bit of information out there, but here&amp;rsquo;s some links that might be helpful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/welcome.html&#34;&gt;Lambda Developer Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/programming-model.html&#34;&gt;Building Lambda functions with Nodejs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/sdk-for-node-js/&#34;&gt;The AWS SDK for Nodejs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/sqs/&#34;&gt;Amazon Simple Queue Service (SQS)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://serverless.com/framework/docs/&#34;&gt;The Serverless Framework (Docs)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;serverless-framework-getting-started&#34;&gt;Serverless Framework - Getting Started&lt;/h2&gt;

&lt;p&gt;First, we&amp;rsquo;ll install the Serverless Framework.  There&amp;rsquo;s some great directions on how you can do that &lt;a href=&#34;https://serverless.com/framework/docs/getting-started/&#34;&gt;here&lt;/a&gt;, but essentially all you&amp;rsquo;ll be doing is running &lt;code&gt;npm install -g serverless&lt;/code&gt;.  This will install the cli tools for the framework, accessible through the &lt;code&gt;sls&lt;/code&gt; or &lt;code&gt;serverless&lt;/code&gt; commands.&lt;/p&gt;

&lt;p&gt;Now we can initialize a new project directory and create our serverless functions.  First, create a root project directory for yourself.  Mine will be &lt;code&gt;~/projects/voting-project/&lt;/code&gt;. I also chose to add a subdirectory in this root folder called &lt;code&gt;serverless-functions&lt;/code&gt;, just to keep the serverless portion of this service separated.  I&amp;rsquo;ll use this location to store all of my Lambda functions for the project.  So, let&amp;rsquo;s &lt;code&gt;cd&lt;/code&gt; into this directory and run the below command.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sls create —template aws-nodejs —path voting-service&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This command will create all of the necessary files for your serverless function, using a Node.js template.  Let&amp;rsquo;s open the &lt;code&gt;handler.js&lt;/code&gt; file (full path: &lt;code&gt;~/projects/voting-project/serverless-functions/voting-service/handler.js&lt;/code&gt;). This file contains some boilerplate code for a Node.js lambda function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// handler.js
&#39;use strict&#39;;

module.exports.hello = async (event) =&amp;gt; {
  return {
    statusCode: 200,
    body: JSON.stringify({
      message: &#39;Go Serverless v1.0! Your function executed successfully!&#39;,
      input: event,
    }),
  };

  // Use this code if you don&#39;t use the http event with the LAMBDA-PROXY integration
  // return { message: &#39;Go Serverless v1.0! Your function executed successfully!&#39;, event };
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can deploy this function immediately, if we wanted to!  Just &lt;code&gt;cd&lt;/code&gt; into this directory - the &lt;code&gt;…/voting-service/&lt;/code&gt; directory - and run &lt;code&gt;sls deploy&lt;/code&gt;.  This will create a CloudFormation template and run it in AWS, which you can see in the AWS Management Console.  Then, to get rid of &lt;em&gt;everything&lt;/em&gt; that this deploy command did, you can either run &lt;code&gt;sls remove&lt;/code&gt; or you can open the CloudFormation stack in AWS and delete the stack manually.&lt;/p&gt;

&lt;p&gt;This intro template from &lt;code&gt;serverless&lt;/code&gt; would only be this single Lambda function and nothing else.  What we need is a function that handles data and adds it to a SQS queue and an API endpoint to send our voting data to.  Let&amp;rsquo;s add those things now.&lt;/p&gt;

&lt;h2 id=&#34;add-an-api-endpoint&#34;&gt;Add an API Endpoint&lt;/h2&gt;

&lt;p&gt;The main benefit of using the Serverless Framework comes from the &lt;code&gt;serverless.yml&lt;/code&gt; file.  This file defines not only your serverless functions, but any other services and rules related to these functions.  There is quite a bit of documentation on this file (and other parts of the framework), which you can find &lt;a href=&#34;https://serverless.com/framework/docs/&#34;&gt;here&lt;/a&gt;. To add an API endpoint, all it takes is to update our &lt;code&gt;serverless.yml&lt;/code&gt; file to contain the right bits of information.  Here&amp;rsquo;s the final result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# serverless.yml
service: voting-service

provider:
  name: aws
  region: us-east-1
  runtime: nodejs8.10
  stage: dev


functions:
  post-vote:
    handler: post-vote.postVote
    events:
      - http:
          path: vote
          method: post
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In short, what we do here is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Define our service name (at the top)&lt;/li&gt;
&lt;li&gt;Define the provider information we&amp;rsquo;d like to use.  In our case, we&amp;rsquo;re using AWS in the us-east-1 region, the runtime for our function will be nodejs, and we&amp;rsquo;d like to set our deployment stage as &lt;code&gt;dev&lt;/code&gt; for the moment.&lt;/li&gt;
&lt;li&gt;Define our functions.  We set the first function name to &lt;code&gt;post-vote&lt;/code&gt; and point out that the handler (the actual function) can be found in the &lt;code&gt;post-vote&lt;/code&gt; file at the &lt;code&gt;postVote&lt;/code&gt; function (&lt;code&gt;&amp;lt;file&amp;gt;.&amp;lt;function name&amp;gt;&lt;/code&gt;). Yes, these names are currently wrong.  We&amp;rsquo;ll update them.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Define the Events associated with this function&lt;/strong&gt;.  This is where we set up our API endpoint.  You can also set up many other types of events here which will trigger your Lambda function.  Check out all the event options &lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/events/&#34;&gt;here&lt;/a&gt;.

&lt;ul&gt;
&lt;li&gt;We define the endpoint as HTTP POST, with a url path of &lt;code&gt;/vote/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You&amp;rsquo;ll notice that the names of the file and function in our &lt;code&gt;.yml&lt;/code&gt; file don&amp;rsquo;t match up at the moment.  The &lt;code&gt;postVote&lt;/code&gt; function does not currently exist, and neither does the &lt;code&gt;post-vote&lt;/code&gt; file.  Currently, the &lt;code&gt;serverless.yml&lt;/code&gt; file would have to show &lt;code&gt;handler.hello&lt;/code&gt; for our function to work properly.  Let&amp;rsquo;s update that &lt;code&gt;.js&lt;/code&gt; file now before we test and deploy this API endpoint.  We&amp;rsquo;ll change the names of the file and function and update the code within.&lt;/p&gt;

&lt;h2 id=&#34;building-our-serverless-function&#34;&gt;Building our Serverless Function&lt;/h2&gt;

&lt;p&gt;First, a quick update of the file name.  We&amp;rsquo;ll name the file &lt;code&gt;post-vote.js&lt;/code&gt; and update the function name to &lt;code&gt;postVote&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// hanlder.js --&amp;gt; post-vote.js
&#39;use strict&#39;;

module.exports.postVote = async (event) =&amp;gt; {
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, now let&amp;rsquo;s throw some useful code in this file.  Currently, our function simply accepts the &lt;code&gt;event&lt;/code&gt; object provided by the API endpoint and returns an object with a &lt;code&gt;200&lt;/code&gt; status code and a &lt;code&gt;body&lt;/code&gt; property containing a simple message and the &lt;code&gt;event&lt;/code&gt; object.  Let&amp;rsquo;s update this so that, instead, we collect our voting data from the &lt;code&gt;event&lt;/code&gt; parameter and add this voting data to a specific SQS queue.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;quot;use strict&amp;quot;;
const AWS = require(&amp;quot;aws-sdk&amp;quot;);
const parseEventData = (apiEventData) =&amp;gt; {

  // data should be passed in through query string params
  if (apiEventData.queryStringParameters) {
    return apiEventData.queryStringParameters;
  }

  return null;
};

AWS.config.update({region: &amp;quot;us-east-1&amp;quot;});

module.exports.postVote = async (event, context) =&amp;gt; {
  const sqs = new AWS.SQS({apiVersion: &amp;quot;2012-11-05&amp;quot;});
  const sns = new AWS.SNS({apiVersion: &amp;quot;2010-03-31&amp;quot;});
  let voteQueueUrl;
  let voteData;

  voteData = parseEventData(event);

  if (!voteData) {
    return {
      statusCode: 500,
      isBase64Encoded: false,
      headers: {
        &amp;quot;Content-Type&amp;quot;: &amp;quot;text/plain&amp;quot;
      },
      body: JSON.stringify({
        awsRequestId: context.awsRequestId,
        error: {
          message: &amp;quot;No query string parameters were found!&amp;quot;
        },
        input: event
      })
    };

  }
  
  try {
    voteQueueUrl = await sqs.getQueueUrl({
      QueueName: process.env.SQS_QUEUE_NAME,
    }).promise();
  
    await sqs.sendMessage({
      MessageBody: JSON.stringify(voteData),
      QueueUrl: voteQueueUrl.QueueUrl
    }).promise();
    console.log(&amp;quot;SQS message sent successfully!&amp;quot;);
  } catch (err) {
    console.error(`SQS message send FAILED. Error: ${err}`);
  }

  // notify our second function that there&#39;s a new vote to handle
  try {
    await sns.publish({
      Message: &amp;quot;New Vote Posted!&amp;quot;,
      TopicArn: process.env.SNS_TOPIC_ARN
    });
    console.log(&amp;quot;SNS published successfully!&amp;quot;);
  } catch (err) {
    console.error(`SQS message send FAILED. Error: ${err}`);
  }


  return {
    statusCode: 200,
    headers: {
      &amp;quot;Content-Type&amp;quot;: &amp;quot;text/plain&amp;quot;
    },
    isBase64Encoded: false,
    body: JSON.stringify({
      awsRequestId: context.awsRequestId,
      message: &amp;quot;Vote successfully processed.&amp;quot;,
      input: event
    })
  };
};

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A couple of things to go over here.  First, the AWS SDK is made available in Lambda to all supported languages.  In Nodejs, this is the &lt;code&gt;aws-sdk&lt;/code&gt; package.  This package allows us to access other AWS services, in this case the SQS service.  Also, when using the AWS SDK, we always want to specify the region we&amp;rsquo;re working in as well as a specific API version for the service that we use.  We&amp;rsquo;ve done that here near the top of the file.  Let&amp;rsquo;s go over the code in a bit more detail.&lt;/p&gt;

&lt;p&gt;First, we require the &lt;code&gt;aws-sdk&lt;/code&gt; and establish a function for parsing the event data (provided by the API endpoint).  Our endpoint will be set up with &amp;ldquo;Lambda Proxy&amp;rdquo; enabled by default, which means the &lt;code&gt;event&lt;/code&gt; object passed in to our function will have quite a bit of information in it.  This also means that our response from this function needs to have a &lt;code&gt;body&lt;/code&gt; which is formatted properly.  We&amp;rsquo;ll just use the &lt;code&gt;JSON.stringify()&lt;/code&gt; method for this.&lt;/p&gt;

&lt;p&gt;We then set up a quick function for processing the data from our &lt;code&gt;event&lt;/code&gt; object.  In our case, all we want to do is make sure that &lt;code&gt;event&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; an object and that it contains the &lt;code&gt;queryStringParameters&lt;/code&gt; property.  This is where our voting data should be found.  If these things aren&amp;rsquo;t available, we&amp;rsquo;ll just throw an error with a quick message explaining that the voting data was not passed in correctly to the API endpoint.  This error can be caught in our &lt;code&gt;async&lt;/code&gt; function and returned to the client with an appropriate status code.  But if all goes well, we&amp;rsquo;ll return the &lt;code&gt;queryStringParameters&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In our main function, &lt;code&gt;postVote&lt;/code&gt;, we first initialize the SQS and &lt;code&gt;SNS&lt;/code&gt; objects and initialize the variables we&amp;rsquo;ll use in this function.  Then, we get our voting data from the &lt;code&gt;event&lt;/code&gt; parameter, using the function we created.  If the no voting data was found, we&amp;rsquo;ll return a &lt;code&gt;400&lt;/code&gt; status code and the error as a property of &lt;code&gt;body&lt;/code&gt;. If we do have data, we&amp;rsquo;ll continue by collecting the URL of our SQS queue and then adding a new message to this queue.  This bit will be in a try / catch block so that, if we hit any problems here, we can log an error message with the details.  After this, we&amp;rsquo;ll publish an SNS message.  This will serve as one of the triggers for our next lambda function.  This other function will be subscribed to this SNS topic and will be triggered whenever we publish to that topic.  Again, we surround the publishing of the SNS message in a try / catch so that we can log a specific error if something goes wrong with this part.  Finally, if we ran everything successfully in our main &lt;code&gt;postVote&lt;/code&gt; function, we&amp;rsquo;ll return a 200 status and a success message in the body.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;An important thing to note in our above code is that most functions in the AWS SDK will be asynchronous calls, and can be made into a Nodejs &lt;code&gt;Promise&lt;/code&gt; by calling the &lt;a href=&#34;https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Request.html#promise-property&#34;&gt;&lt;code&gt;.promise()&lt;/code&gt;&lt;/a&gt; function on the &lt;a href=&#34;https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Request.html&#34;&gt;&lt;code&gt;AWS Request&lt;/code&gt;&lt;/a&gt; object (returned by &lt;code&gt;getQueueUrl&lt;/code&gt; and &lt;code&gt;sendMessage&lt;/code&gt; in our case).  This returns a &lt;code&gt;Promise&lt;/code&gt; instead of using the callback, which allows us to use &lt;code&gt;async&lt;/code&gt; and &lt;code&gt;await&lt;/code&gt; to write cleaner code!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;permissions&#34;&gt;Permissions&lt;/h2&gt;

&lt;p&gt;If you&amp;rsquo;ve worked in AWS before, you&amp;rsquo;ll know that we need to set up some permissions here in order for these functions to run properly. Our Lambda function will have a couple of permissions by default - logging to CloudWatch, for example, which is done with the &lt;code&gt;console.log&lt;/code&gt; statements - but it won&amp;rsquo;t have the ability to do things in SQS or SNS unless we explicitly give those permissions to it.  This is done through IAM Roles.&lt;/p&gt;

&lt;p&gt;With the Serverless framework, we can set up a role within our code.  This makes management of the service as a whole much easier.  To do this, we&amp;rsquo;ll open up the &lt;code&gt;serverless.yml&lt;/code&gt; file again and make some changes.  Here&amp;rsquo;s the result:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;service: voting-app

provider:
  name: aws
  runtime: nodejs8.10
  stage: ${opt:stage, &#39;dev&#39;}
  region: ${opt:region, &#39;us-east-1&#39;}
  environment:
    SQS_QUEUE_NAME: ${self:service}-${self:provider.stage}-queue
    SNS_TOPIC: ${self:service}-${self:provider.stage}-topic
  iamRoleStatements:
    - Effect: Allow
      Action:
        - SQS:*
      Resource: {&amp;quot;Fn::Join&amp;quot; : [&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sqs:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SQS_QUEUE_NAME}&amp;quot; ] ] }
    - Effect: Allow
      Action:
        - SNS:*
      Resource: {&amp;quot;Fn::Join&amp;quot;:[&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sns:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SNS_TOPIC}&amp;quot;]]}

functions:
  post-vote:
    handler: post-vote.postVote
    events:
      - http:
          path: vote
          method: post
    environment:
      SNS_TOPIC_ARN: {&amp;quot;Fn::Join&amp;quot;:[&amp;quot;&amp;quot;, [&amp;quot;arn:aws:sns:${self:provider.region}:&amp;quot;, {&amp;quot;Ref&amp;quot;:&amp;quot;AWS::AccountId&amp;quot;}, &amp;quot;:${self:provider.environment.SNS_TOPIC}&amp;quot;]]}

resources:
  Resources:
    VotesQueue:
      Type: &#39;AWS::SQS::Queue&#39;
      Properties:
        QueueName: ${self:provider.environment.SQS_QUEUE_NAME}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing you&amp;rsquo;ve probably noticed is a lot of these: &lt;code&gt;{}&lt;/code&gt;.  What&amp;rsquo;s going on here? Well, in the serverless yaml files you can use variables and functions!  Take a quick look &lt;a href=&#34;https://serverless.com/framework/docs/providers/aws/guide/variables/&#34;&gt;here&lt;/a&gt; to get a good idea on how variables work, and &lt;a href=&#34;https://theserverlessway.com/aws/cloudformation/template-functions/&#34;&gt;here&lt;/a&gt; for a nice blog post on the functions.  Using variables and functions allows us to avoid repeating ourselves - see the &lt;a href=&#34;https://en.wikipedia.org/wiki/Don%27t_repeat_yourself&#34;&gt;DRY Policy&lt;/a&gt; - and also helps keep our naming conventions all the same throughout our pipeline.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;iamRoleStatements&lt;/code&gt; section is where we establish our IAM Roles.  These roles allow our Lambda functions to interact with SQS and SNS.  Here we&amp;rsquo;ve just said &amp;ldquo;Let our service access this specific resource and take any action on it&amp;rdquo; for both SQS and SNS. The resources in question are established at the &lt;code&gt;Resource&lt;/code&gt; fields, where we build an AWS ARN which will specifically point to our SNS Topic and SQS Queue.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve also added &lt;em&gt;environment variables&lt;/em&gt; here for the SQS queue name and the SNS topic name.  These environment variables can be accessed at runtime by our functions!  You may have noticed in our function code above that we are collecting the SQS queue name and SNS topic name from &lt;code&gt;process.env&lt;/code&gt;.  The variables we establish here in the &lt;code&gt;environment&lt;/code&gt; section end up in that &lt;code&gt;process.env&lt;/code&gt; object!&lt;/p&gt;

&lt;p&gt;The last important bit in this file is the &lt;code&gt;resources&lt;/code&gt; section.  This section will create actual AWS resources for us when we run our serverless service!   Here we create a SQS Queue, collecting the Queue Name from our environment variable at the top of the file.&lt;/p&gt;

&lt;h2 id=&#34;finishing-up&#34;&gt;Finishing Up&lt;/h2&gt;

&lt;p&gt;That pretty much does it for this bit of our pipeline.  We can test our function locally by installing the AWS SDK into our local project with &lt;code&gt;npm i aws-sdk&lt;/code&gt; and then running &lt;code&gt;sls invoke local —function post-vote —data &amp;lt;insert data string&amp;gt;&lt;/code&gt;.  Here&amp;rsquo;s an example that I ran locally:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://mct-dev.github.io/images/blog/2019-04-17_sls-invoke-local.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The returned string of JSON doesn&amp;rsquo;t look pretty, but it does show that the function is working properly.  If you had trouble running this locally, you&amp;rsquo;ll likely have to &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&#34;&gt;configure your aws cli&lt;/a&gt; so that the AWS SDK we&amp;rsquo;re using can access your AWS resources.&lt;/p&gt;

&lt;p&gt;To deploy this to AWS, we run &lt;code&gt;sls deploy&lt;/code&gt; within our &lt;code&gt;/serverless-functions/voting-service/&lt;/code&gt; directory.  This will deploy everything that we need into AWS, permissions and all!  Then, if we want to remove all of these resources in AWS we can simply run &lt;code&gt;sls remove&lt;/code&gt; in the same directory.  Simple.&lt;/p&gt;

&lt;p&gt;The next step in our project will be another serverless function which checks our SQS queue for messages and handles these messages appropriately.  We&amp;rsquo;ll build this bit in &lt;a href=&#34;https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/&#34;&gt;the next post of this series&lt;/a&gt;.  See you there!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Netflix Voting Service - Case Study</title>
      <link>https://mct-dev.github.io/posts/aws-sqs-microservice-pipeline/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://mct-dev.github.io/posts/aws-sqs-microservice-pipeline/</guid>
      <description>

&lt;p&gt;This is part 1 of the series.  Feel free to skip around to other sections using the links below.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/aws-sqs-microservice-pipeline/&#34;&gt;Case Study and Grooming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/&#34;&gt;Simple API Endpoints with Serverless and Lambda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mct-dev.github.io/posts/handling-sqs-messages-with-serverless/&#34;&gt;Handling SQS Messages with Serverless Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;case-study&#34;&gt;Case Study&lt;/h2&gt;

&lt;p&gt;We are working at Netflix.  Yep, you and me both.  Our company, Netflix, has recently implemented their voting functionality where users can vote on different aspects of the show or movie they just watched.  We have been tasked with creating a pipeline which can receive and process an extremely large number of these votes in the most efficient, scalable, and cost effective way possible.&lt;/p&gt;

&lt;h2 id=&#34;grooming&#34;&gt;Grooming&lt;/h2&gt;

&lt;p&gt;In this scenario, we can assume that the data will be passed from the front end as JSON.  The JSON will have a particular structure and we will have to provide a URL endpoint where the JSON can be sent.  Since the quantity of votes received per second or minute may change dramatically based on time of day or any number of other factors, we likely do not want to have a powerful server running all the time waiting to collect these votes.  This seems like an ideal situation for an &lt;a href=&#34;https://aws.amazon.com/api-gateway/&#34;&gt;AWS API Gateway&lt;/a&gt; connected to 1 or more serverless &lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;Lambda&lt;/a&gt; functions.&lt;/p&gt;

&lt;p&gt;We could probably use just 1 Lambda function to receive the data, verify and sanitize it, and then post it to our database, but that seems like a little bit much for just 1 little function.  We should probably have more than 1 function, each with a very specific job.  For this scenario, let&amp;rsquo;s go with 1 function to receive the data, 1 to process the data, and 1 to add it to our database.&lt;/p&gt;

&lt;p&gt;Since we may end up with an extremely high volume of calls to our API - think thousands of requests per second - it would be a good idea for us to &amp;ldquo;decouple&amp;rdquo; our pipeline.  We&amp;rsquo;ll achieve this by using &lt;a href=&#34;https://aws.amazon.com/sqs/&#34;&gt;AWS SQS&lt;/a&gt; as a message queue service in between our very first &amp;ldquo;receiver&amp;rdquo; function and the rest of our serverless pipeline.  SQS will allow us to store a queue of messages which contain the data submitted through the API endpoint.  Then, later on, we can ask this queue for messages to process.  The key here is that we don&amp;rsquo;t have to &lt;em&gt;immediately&lt;/em&gt; process and store the data from the API request.  We can add it to the queue, then process items from the queue in a more leisurely fashion.  This &amp;ldquo;decoupling&amp;rdquo; of our pipeline will help reduce the stress on our database and also helps keep our pipeline scalable and manageable.&lt;/p&gt;

&lt;p&gt;For this scenario, we will use &lt;a href=&#34;https://aws.amazon.com/dynamodb/&#34;&gt;Dynamo DB&lt;/a&gt; because it is flexible, cost-efficient, and highly scalable. It also has the added benefit of very smooth interoperability with Lambda and other AWS services.&lt;/p&gt;

&lt;p&gt;So, in summary, our project should include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An API endpoint (1 or more) for a front end to send vote data to.&lt;/li&gt;
&lt;li&gt;A Lambda function which will collect the data from this API endpoint and add it to&amp;hellip;&lt;/li&gt;
&lt;li&gt;…an SQS message queue.&lt;/li&gt;
&lt;li&gt;1 or more Lambda functions which will periodically ask the SQS message queue if there are any messages to process and, if so, process these messages (votes) and add them to&amp;hellip;&lt;/li&gt;
&lt;li&gt;…a Dynamo DB table.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s get started!  The &lt;a href=&#34;https://mct-dev.github.io/posts/simple-api-endpoints-with-serverless-and-lambda/&#34;&gt;next post&lt;/a&gt; in this series will go over the first segment of our pipeline: the API gateway and the initial Lambda function.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://mct-dev.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://mct-dev.github.io/about/</guid>
      <description>

&lt;h1 id=&#34;mike&#34;&gt;Mike&lt;/h1&gt;
</description>
    </item>
    
  </channel>
</rss>